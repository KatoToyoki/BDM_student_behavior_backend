# Log4j2 Configuration for Spark Cluster
# Optimized for production monitoring and debugging

# Root logger configuration
rootLogger.level = INFO
rootLogger.appenderRefs = stdout, file
rootLogger.appenderRef.stdout.ref = console
rootLogger.appenderRef.file.ref = RollingFileAppender

# Console Appender
appender.console.type = Console
appender.console.name = console
appender.console.target = SYSTEM_OUT
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n

# Rolling File Appender
appender.RollingFileAppender.type = RollingFile
appender.RollingFileAppender.name = RollingFileAppender
appender.RollingFileAppender.fileName = /opt/spark/logs/spark.log
appender.RollingFileAppender.filePattern = /opt/spark/logs/spark-%i.log.gz
appender.RollingFileAppender.layout.type = PatternLayout
appender.RollingFileAppender.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n
appender.RollingFileAppender.policies.type = Policies
appender.RollingFileAppender.policies.size.type = SizeBasedTriggeringPolicy
appender.RollingFileAppender.policies.size.size = 100MB
appender.RollingFileAppender.strategy.type = DefaultRolloverStrategy
appender.RollingFileAppender.strategy.max = 10

# Specific logger configurations
# Reduce verbosity for common noisy loggers
logger.akka.name = akka
logger.akka.level = WARN

logger.netty.name = io.netty
logger.netty.level = WARN

logger.hive.name = org.apache.hadoop.hive
logger.hive.level = WARN

logger.spark.name = org.apache.spark
logger.spark.level = INFO

# SQL execution logging (useful for debugging query performance)
logger.sparkSql.name = org.apache.spark.sql
logger.sparkSql.level = INFO

# Task and stage logging
logger.scheduler.name = org.apache.spark.scheduler
logger.scheduler.level = INFO

# Memory and storage logging
logger.storage.name = org.apache.spark.storage
logger.storage.level = INFO

# Network and shuffle logging
logger.network.name = org.apache.spark.network
logger.network.level = INFO

# Python process logging
logger.python.name = org.apache.spark.api.python
logger.python.level = INFO

# Application-specific logging
logger.app.name = spark.app
logger.app.level = INFO